{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0db7a2b2-5dbf-40f6-96b4-fb135e7c0bbb",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1 id='content-based-filtering' style='color:#7159c1; font-size:350%'>Collaborative Filtering</h1>\n",
    "    <i style='font-size:125%'>Recommendations of Items from Similar Users</i>\n",
    "</center>\n",
    "\n",
    "> **Topics**\n",
    "\n",
    "```\n",
    "- ✨ Content-Based Filtering Problems\n",
    "- ✨ Collaborative Filtering\n",
    "- ✨ User Based Approach\n",
    "- ✨ K-Nearest Neighbors\n",
    "- ✨ K-Nearest Neighbors Basic VS K-Nearest Neighbors With Means VS K-Nearest Neighbors With Z-Score\n",
    "- ✨ Grid Search CV VS Randomized Search CV\n",
    "- ✨ Hands-on\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02f08f2-8ac2-42d6-bcd5-bfd329df2c97",
   "metadata": {},
   "source": [
    "<h1 id='0-content-based-filtering-problems' style='color:#7159c1; border-bottom:3px solid #7159c1; letter-spacing:2px; font-family:JetBrains Mono; font-weight: bold; text-align:left; font-size:240%;padding:0'>✨ | Content-Based Filtering Problems</h1>\n",
    "\n",
    "In the previous two notebooks, we dived into Content-Based Filtering with Plot Description and Metadatas approach and got better recommendations results!!\n",
    "\n",
    "Nonetheless, you may be wondering: *\"Okay, where is the catch? Is this method really perfect? Are there any problems with it?\"*. And yes, even though giving better results, there are some cons on Content-Based Filtering.\n",
    "\n",
    "The first problem is that the recommendations are based on similiar items regardless the user tastes. Picture this, if user A and user B are into Mob Psycho 100, they both will receive the same similar animes recommendations, regardless their animes tastes and, consequently, a Recommendation Bubble is created.\n",
    "\n",
    "Besides, people tastes change over the time, so, even though user A are into shounen animes like Mob Psycho 100 today, in a few weeks this very user can be into slice-of-life animes and, since the given recommendations will be using Mob Psycho 100 as a parameter, the user will not receive any slice-of-life animes recommendations, leading to the user search for another platform to watch what he is looking for.\n",
    "\n",
    "Thus, in order to minimize these problems, a new recommendation method has been made up: `Collaborative Filtering`!! Let's find out what it is and how it works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13085e0e-900f-4ed6-a50c-fdc45b33d8d1",
   "metadata": {},
   "source": [
    "<h1 id='1-collaborative-filtering' style='color:#7159c1; border-bottom:3px solid #7159c1; letter-spacing:2px; font-family:JetBrains Mono; font-weight: bold; text-align:left; font-size:240%;padding:0'>✨ | Collaborative Filtering</h1>\n",
    "\n",
    "`Collaborative Filtering` reccomends animes that similar users liked, being able to get closer to the real users tastes. If you use Netflix, you probably already stumbled upon to some series marked as `For you`. If that's so, congrats, that is a real-world Collaborative Filtering Recommendation!! To make things even clearer, assume that two similar users, user A and user B, like Demon Slayer, and user B is also into Grand Blue, so the platform will recommend Grand Blue to user A.\n",
    "\n",
    "Besides, this Filtering has two modes: 1) `User-Based`, where the user receives recommendations from items that similar users liked; and 2) `Item-Based`, where the user receives recommendations from items that similar users liked and the current user may well rate the recommended item.\n",
    "\n",
    "\n",
    "About the advantages:\n",
    "\n",
    "> **Better Recommendations** - `since it recommends animes that similar users liked, this system method tends to get closer to the user tastes when compared to Content-Based and Demographic Filtering`;\n",
    "\n",
    "> **Personalized Recommendations** - `even though two users are searching for recommendations using the same anime, for instance Mob Psycho 100, both of them will receive different recommendations due to their tastes`;\n",
    "\n",
    "> **Low Bubble of Recommendations** - `consequently, the probability of a Bubble of Recommendations be created is low and, even if one is created, it will be small`.\n",
    "\n",
    "<br />\n",
    "\n",
    "Disadvantages-wise:\n",
    "\n",
    "> **More Data Required** - `ir order to get closer to users tastes, in addition to having animes data, it is needed to have users data, such as their ratings on previously watched animes`;\n",
    "\n",
    "> **Bubble of Recommendations** - `even though the probability of a small Bubble of Recommendations be created is low, there is yet the risk of it be happening`;\n",
    "\n",
    "> **Outliers** - `it is needed to add a cut-off of users ratings and mean rating score by user in order to avoid outliers in the recommendations. For instance, consider that user A rated 100 animes with 1 score and the very user mean score of all rated animes is 1.5, it means that the user bad rated all animes he watched and, consequently, may be up no good in the platform giving outliers to the ratings`;\n",
    "\n",
    "> **More Computational Cost and Power** - `Collaborative-Filtering Algorithms are more complex and sofisticated to the previously ones, then, more computational cost and power is needed to run them`.\n",
    "\n",
    "<br />\n",
    "\n",
    "The image below ilustrates how this technique works:\n",
    "\n",
    "<br />\n",
    "\n",
    "<figure style='text-align:center'>\n",
    "    <img style='border-radius:20px' src='./assets/2-collaborative-filtering.png' alt='Collaborative Filtering Diagram' />\n",
    "    <figcaption>Figure 1 - Collaborative Filtering Diagram. By <a href='https://www.analyticsvidhya.com/blog/2022/02/introduction-to-collaborative-filtering/'>Shivam Baldha - Introduction to Collaborative Filtering©</a>.</figcaption>\n",
    "</figure>\n",
    "\n",
    "<br /><br />\n",
    "\n",
    "In this notebook, we are going further to User-Based technique and use K-Nearest Neighbors to find similar users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ca383d-135b-425a-80f6-34d0d32c5e64",
   "metadata": {},
   "source": [
    "<h1 id='2-user-based-approach' style='color:#7159c1; border-bottom:3px solid #7159c1; letter-spacing:2px; font-family:JetBrains Mono; font-weight: bold; text-align:left; font-size:240%;padding:0'>✨ | User-Based Approach</h1>\n",
    "\n",
    "In a few words, consider a person called user E, the `Collaborative Filtering User-Based Approach` works on finding similar users to user E and then recommendating to him similar items that the similar users liked.\n",
    "\n",
    "To do it, the Algorithm first calculates the similarity between the users using `Pearson Correlation, Cosine Similarity or other metric`, then predicts the rate user E would give to the animes that the most similar users have watched and recommends the most predicted, rated ones.\n",
    "\n",
    "For example, consider the following situation where want to recommend movies to user E. The first step is to calculate the similarity of the others users to this one. The image below ilustrates the situation:\n",
    "\n",
    "<br />\n",
    "\n",
    "<figure style='text-align:center'>\n",
    "    <img style='border-radius:20px' src='./assets/18.0-collaborative-filtering-user-based.png' alt='Collaborative Filtering example using User-Based approach' />\n",
    "    <figcaption>Figure 2 - Board ilustrating the similarity of the users to user E. The indexes are the users, the columns are the movies and the users rates to the movies and the last column is the similarity of the users to user E. The similarity has been calculated using Pearson Correlation. Besides, since user A and F have not rated movies that user E has been, their similarity is 0 (NaN). Since the similarity is being calculated to user E, user E has full similarity to itself; also, user D is totally different to user E due to the similarity be -1. By <a href='https://www.kaggle.com/code/ibtesama/getting-started-with-a-movie-recommendation-system'>Sibtesam Ahmed - Getting Started with a Movie Recommendation System©</a>.</figcaption>\n",
    "</figure>\n",
    "\n",
    "<br /><br />\n",
    "\n",
    "After calculating the similarities, we have to predict the ratings that user E would give to the movies he hasn't rated and then, recommends to him the movies liked by the most similar users and that got the higher predicted ratings from user E. The following image pictures the results:\n",
    "\n",
    "<br />\n",
    "\n",
    "<figure style='text-align:center'>\n",
    "    <img style='border-radius:20px' src='./assets/18.1-collaborative-filtering-user-based.png' alt='Collaborative Filtering example results using User-Based approach' />\n",
    "    <figcaption>Figure 3 -Board ilustrating the results of the Collaborative Filtering. The predicted ratings of user E are marked with asterisks (*). The most similar users to user E are C and B. Probably, Avengers would be the recommended movie since its the movie that a similar user (B) has liked and got a high predicted rating to user E. By <a href='https://www.kaggle.com/code/ibtesama/getting-started-with-a-movie-recommendation-system'>Sibtesam Ahmed - Getting Started with a Movie Recommendation System©</a>.</figcaption>\n",
    "</figure>\n",
    "\n",
    "<br /><br />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d0805a-f6a8-4e8f-b5f6-bd40f7b137d1",
   "metadata": {},
   "source": [
    "<h1 id='3-k-nearest-neighbors' style='color:#7159c1; border-bottom:3px solid #7159c1; letter-spacing:2px; font-family:JetBrains Mono; font-weight: bold; text-align:left; font-size:240%;padding:0'>✨ | K-Nearest Neighbors</h1>\n",
    "\n",
    "Instead of be using Pearson Correlation or Cosine Similarity to find similar users to a given one, we are going further and to apply `K-Nearest Neighbors` to do this task. This algorithm does one thing different than what has been done in the example from the previous section: instead of finding similar users, it consider that the users are grouped into clusters and its major goal is to find the most similar cluster to a given user.\n",
    "\n",
    "K-Nearest Neighbores works like this:\n",
    "\n",
    "> 1 - group the users into clusters (when the categories are known, we can stick into them. When the categories are unknown, we can use Unsupervisioned Machine Learning Algorithms, such as `K-Means Clustering`, to cluster the data);\n",
    "\n",
    "> 2 - for a given user, find the K nearest neighbors, being \"K\" the number of nearest neighbors to be considered;\n",
    "\n",
    "> 3 - when \"K\" is equals to 1, the given user is similar to the cluster of the unique nearest neighbor. When \"K\" is greater than 1, the given user is similar to the cluster of the most nearest neighbors belong. If there are a tie, we randomly choose one of the tied clusters to the given user be similar (picture that the user E has 5 nearest neighbors from cluster Red and 5 others from cluster Blue. Since both clusters has the same amount of users chosen as nearest neighbors to the given user, we randomly choose between Red and Blue to the very user be similar to).\n",
    "\n",
    "<br />\n",
    "\n",
    "The image below pictures an example of the clustering:\n",
    "\n",
    "<br />\n",
    "\n",
    "<figure style='text-align:center'>\n",
    "    <img style='border-radius:20px' src='./assets/19-k-nearest-neighbors.png' alt='Example of K-Nearest Neighbors Algorithm assigning a cluster to a given data point' />\n",
    "    <figcaption>Figure 4 - Example of K-Nearest Neighbors Algorithm assigning a cluster to a given data point. By <a href='https://www.youtube.com/watch?v=HVXime0nQeI'>StatQuest with Josh Starmer - StatQuest: K-nearest neighbors, Clearly Explained©</a>.</figcaption>\n",
    "</figure>\n",
    "\n",
    "<br /><br />\n",
    "\n",
    "About the value of Nearest Neighbors (K) to be taken, we have to consider these information:\n",
    "\n",
    "> 1 - There is no phisical or biological way to determine the best value for \"K\", so you may have to try a few out values  before settling on one. Do this by pretending part of the training data is \"unknown\";\n",
    "\n",
    "> 2 - Low values for K, such as K=1 or K=2, can be noisy and subject to the effects of outliers;\n",
    "\n",
    "> 3 - Large values for K smooth over things, but you do not want to K be so large that a category with only a few samples in it will always be out voted by other categories.\n",
    "\n",
    "<br />\n",
    "\n",
    "For better explanations about how K-Nearest Neighbors and K-Means Clustering work, consider watching these two videos provided by [StatQuest with Josh Starmer](https://www.youtube.com/@statquest): [StatQuest: K-nearest neighbors, Clearly Explained](https://www.youtube.com/watch?v=HVXime0nQeI) and [StatQuest: K-means clustering](https://www.youtube.com/watch?v=4b5d3muPQmA)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d148d054-4fcd-4780-a5c0-7000bf8611f0",
   "metadata": {},
   "source": [
    "<h1 id='4-k-nearest-neighbors-basic-vs-k-nearest-neighbors-with-means-vs-k-nearest-neighbors-with-z-score' style='color:#7159c1; border-bottom:3px solid #7159c1; letter-spacing:2px; font-family:JetBrains Mono; font-weight: bold; text-align:left; font-size:240%;padding:0'>✨ | K-Nearest Neighbors Basic VS K-Nearest Neighbors With Means VS K-Nearest Neighbors With Z-Score</h1>\n",
    "\n",
    "The K-Nearest Neighbors (KNN) has some variations in its algorithms in other to get better results in especific situations, the main three ones are `Basic`, `With Means` and `With Z-Score` variations, let's see their description and settle which one to use in the project:\n",
    "\n",
    "> **K-Nearest Neighbors Basic** - `known as the vanilla version, this one is the first KNN Algorithm and has been explained in the previous section`;\n",
    "\n",
    "> **K-Nearest Neighbors With Means** - `this one is like the Basic version, with the addition of the mean ratings of each user in order to avoid outliers and give different weights to the users accordingly to their mean ratings`;\n",
    "\n",
    "> **K-Nearest Neighbors With Z-Score** - `this one is like the With Means version, with the addition of the Z-Score Normalization of each user mean rating`.\n",
    "\n",
    "Since assigning different weights to the users accordingly to their mean rating is a great idea to get more accurate results and since the ratings dataset is not normalized, we are going to stick to `K-Nearest Neighbors With Means` from now on!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa895b6-1859-4920-9d04-cb641ab5d829",
   "metadata": {},
   "source": [
    "<h1 id='5-grid-search-cv-vs-randomized-search-cv' style='color:#7159c1; border-bottom:3px solid #7159c1; letter-spacing:2px; font-family:JetBrains Mono; font-weight: bold; text-align:left; font-size:240%;padding:0'>✨ | Grid Search CV VS Randomized Search CV</h1>\n",
    "\n",
    "Okay, now that we already have chosen the model to find similar users, we have to find the best hyperparameters to it. Hyperparameters are those ones that the algorithm cannot learn by itself over the training step and it is a task for ur to choose the best values in order to the model provide the best results.\n",
    "\n",
    "For K-Nearest Neighbors, the hyperparameters we are going to consider are the `Similarity Metric, User-Based Approach, Minimum Number of Similar Items and Minimum and Maximum Number of Nearest Neighbors`.\n",
    "\n",
    "Fortunately, there are some techniques we can use instead of trying a bunch of random values, such as `Grid Search CV` and `Randomized Search CV`, being:\n",
    "\n",
    "> **Grid Search CV** - `tests the permutation of all hyperparameters and returns the values that made the model got the best results. This approach is recommended for small datasets`;\n",
    "\n",
    "> **Randomized Search CV** - `tests some random permutations of the hyperparameters and returns the values that made the model got the best results. This approach is recommended for large datasets`.\n",
    "\n",
    "For a better understanding, consider we have two hyperparameters $A=[1, 2, 3]$ and $B=[4, 5, 6]$. In Grid Search CV, all permutations are tested, that is, all A-B pairs into $pairs = [(1, 4), (1, 5), (1, 6), (2, 4), (2, 5), (2, 6), (3, 4), (3, 5), (3,6)]$ are tested; whereas in Randomized Search CV, only a few random A-B pairs are tested.\n",
    "\n",
    "Since our ratings dataset is kind of large - over than 23 million observations!! -, we are going to stick to `Randomized Search CV`.\n",
    "\n",
    "Besides, notice that the Recommendation Problem has been turned into an Optimization Problem, where we should find out the Unsupervisioned Machine Learning Algorithm and the Hyperparameters Values that fit the problem best. Now, let's go to the code!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7728b40f-30c2-41c4-b7b8-d277dd5cc02a",
   "metadata": {},
   "source": [
    "<h1 id='6-hands-on' style='color:#7159c1; border-bottom:3px solid #7159c1; letter-spacing:2px; font-family:JetBrains Mono; font-weight: bold; text-align:left; font-size:240%;padding:0'>✨ | Hands-on</h1>\n",
    "\n",
    "```\n",
    "- Settings\n",
    "- Reading Datasets\n",
    "- Dropping Variables\n",
    "- Getting Random Observations for Hyperparameter Tuning\n",
    "- Finding Best Hyperparameters for the Model\n",
    "- Splitting Dataset into Training and Validation\n",
    "- Training the Model\n",
    "- Recommendations\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39e26f0-154e-4d3c-9b82-713e98bd5f24",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**- Settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b128c5a6-5cae-4c27-9161-2df224901510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------\n",
    "# ---- Imports ----\n",
    "# -----------------\n",
    "import inflect       # pip install inflect\n",
    "import numpy as np   # pip install numpy\n",
    "import pandas as pd  # pip install pandas\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# ---- Surprise Imports ----\n",
    "# --------------------------\n",
    "#\n",
    "# pip install scikit-surprise\n",
    "#\n",
    "# If you get any problems installing the package, follow the steps in this Stack Overflow link:\n",
    "# - https://stackoverflow.com/questions/44951456/pip-error-microsoft-visual-c-14-0-is-required\n",
    "#\n",
    "from surprise import accuracy\n",
    "from surprise import KNNWithMeans\n",
    "from surprise.dataset import Dataset\n",
    "from surprise.model_selection.validation import cross_validate\n",
    "from surprise.reader import Reader\n",
    "from surprise.model_selection import RandomizedSearchCV\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -------------------\n",
    "# ---- Constants ----\n",
    "# -------------------\n",
    "DATASETS_PATH = ('./datasets')\n",
    "INFLECT_ENGINE = (inflect.engine())\n",
    "SEED = (20240106)\n",
    "SURPRISE_READER = (Reader())\n",
    "\n",
    "HYPERPARAMETER_TUNING_SAMPLE_SIZE = 10000 # my laptop does not support more than 10,000. I need more RAM :(\n",
    "TRAINING_DF_SIZE = (0.80)\n",
    "VALIDATION_DF_SIZE = (0.20)\n",
    "\n",
    "SIMILARITY_OPTIONS = {\n",
    "    'name': ['cosine', 'pearson', 'pearson_baseline', 'msd'] # similarity metrics: the best one will be used for recommendations;\n",
    "    , 'user_based': [True] # True: User-Based Approach; False: Item-Based Approach;\n",
    "    , 'min_support': [3, 4, 5] # User-Based: minimum number of similar items to be considered; Item-Based: minimum number of similar users to be considered.\n",
    "}\n",
    "KNN_PARAMS = {\n",
    "    'k': [30, 40, 50]              # list of maximum nearest neighbors to be considered: the best one will be used for recommendations;\n",
    "    , 'min_k': [20, 25, 30]        # minimum number of nearest neighbors to be considered;\n",
    "    , 'sim_options': SIMILARITY_OPTIONS # similarity parameters;\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ------------------\n",
    "# ---- Settings ----\n",
    "# ------------------\n",
    "np.random.seed(SEED)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -------------------\n",
    "# ---- Functions ----\n",
    "# -------------------\n",
    "def find_best_hyperparameters_values(model, search_cv, parameters, dataset):\n",
    "    \"\"\"\n",
    "    \\ Descrition:\n",
    "        - creates a parameter Search CV to find the best score, hyparameters values and estimators for a given\n",
    "    K-Nearest Neighbors model;\n",
    "        - returns the best model and its score, hyperparameters and estimators.\n",
    "    \n",
    "    \\ Parameters:\n",
    "        - model: Chosen Classification model. For this notebook, K-Nearest Neighbors With Means is the chosen one;\n",
    "        - search-cv: Surprise Parameter Search. For this notebook, Randomized Search CV is the chosen one;\n",
    "        - parameters: dictionary of KNN Parameters;\n",
    "        - dataset: Surprise DataFrame.\n",
    "    \"\"\"\n",
    "    classification_model = search_cv(\n",
    "        model\n",
    "        , parameters\n",
    "        , n_jobs=-1                 # number of CPU cores used on models' training and validation (-1 all cores are used)\n",
    "        , measures=['rmse']         # evaluation metrics\n",
    "        , random_state=SEED\n",
    "    )\n",
    "    classification_model.fit(dataset)\n",
    "    \n",
    "    print(f'- Best Score: {classification_model.best_score}')\n",
    "    print(f'- Best Parameters: {classification_model.best_params}')\n",
    "    print(f'- Best Estimator: {classification_model.best_estimator}')\n",
    "    \n",
    "    return classification_model\n",
    "\n",
    "from collections import defaultdict\n",
    "def get_recommendations(predictions, n=10):\n",
    "    # First map the predictions to each user\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "    \n",
    "    # Then sort the predictions for each user and retrieve the k-nearest neighbors and highest ones\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "        \n",
    "    return top_n\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -----------------\n",
    "# ---- Classes ----\n",
    "# -----------------\n",
    "class collaborative_filtering_user_based_approach():\n",
    "    \"\"\"\n",
    "    This classes apply Collaborative Filtering with User Based Approach to recommend 'n' animes to a given user.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, training_df, validation_df, full_dataset):\n",
    "        \"\"\"\n",
    "        \\ Description:\n",
    "            - Class Constructor.\n",
    "        \n",
    "        \\ Parameters:\n",
    "            - Model: Surprise Prediction Model. K-Nearest Neighbors With Means is the chosen one for this notebook;\n",
    "            - Training DF: Surprise DataFrame;\n",
    "            - Validation DF: Surprise DataFrame;\n",
    "            - Full Dataset: Surprise DataFrame (Merge of: Training DF and Validation DF).\n",
    "            \n",
    "        \\ Other Attributes:\n",
    "            - Predictions Validations: Surprise DataFrame;\n",
    "            - Recommendations: \n",
    "            - Top N: Surprise DataFrame;\n",
    "            - Recommendations DF: Pandas DataFrame.\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.training_df = training_df\n",
    "        self.validation_df = validation_df\n",
    "        self.full_dataset = full_dataset\n",
    "        \n",
    "        self.predictions_validations = None\n",
    "        self.recommendations = None\n",
    "        self.top_n = None\n",
    "        self.recommendations_df = None\n",
    "        \n",
    "    def fit_and_predict(self, verbose=True):\n",
    "        \"\"\"\n",
    "        \\ Description:\n",
    "            - Applies training, validation and evaluation steps;\n",
    "            - Gets the top 'n' recommendations;\n",
    "            - Returns the top 'n' recommendations as a Pandas DataFrame.\n",
    "        \n",
    "        \\ Parameters:\n",
    "            - Verbose: Boolean.\n",
    "        \"\"\"\n",
    "        # ---- Training Step ----\n",
    "        if verbose:\n",
    "            fitting_step_title = '** Fitting Step **'\n",
    "            print('*' * len(fitting_step_title))\n",
    "            print(fitting_step_title)\n",
    "            print('*' * len(fitting_step_title))\n",
    "            print('---')\n",
    "            \n",
    "        self.model.fit(self.training_df)\n",
    "        \n",
    "        # ---- Validation Step -----\n",
    "        if verbose:\n",
    "            prediction_step_title = '** Prediction Step **'\n",
    "            print('*' * len(prediction_step_title))\n",
    "            print(prediction_step_title)\n",
    "            print('*' * len(prediction_step_title))\n",
    "            print('---')\n",
    "            \n",
    "        self.predictions_validations = self.model.test(self.validation_df)\n",
    "\n",
    "        # ---- Evaluation Step ----\n",
    "        if verbose:\n",
    "            evaluation_step_title = '** Evaluation Step **'\n",
    "            print('*' * len(evaluation_step_title))\n",
    "            print(evaluation_step_title)\n",
    "            print('*' * len(evaluation_step_title))\n",
    "        \n",
    "        rmse_evaluation = round(accuracy.rmse(self.predictions_validations), 4)\n",
    "        print(f'- Root Mean Squared Error (RMSE) for the predictions: {rmse_evaluation}')\n",
    "        \n",
    "        # ---- Getting Recommendations ----\n",
    "        self.top_n = get_recommendations(self.predictions_validations)\n",
    "        self.recommendations_df = pd.DataFrame(columns=['user_id', 'anime_id', 'rating'])\n",
    "        \n",
    "        for item in self.top_n:\n",
    "            current_recommendation_df = pd.DataFrame(self.top_n[item], columns=['anime_id', 'rating'])\n",
    "            current_recommendation_df['user_id'] = item\n",
    "            recommendation_variables = current_recommendation_df.columns.tolist()\n",
    "            recommendation_variables = recommendation_variables[-1:] + recommendation_variables[:-1]\n",
    "            current_recommendation_df = current_recommendation_df[recommendation_variables]\n",
    "            self.recommendations_df = pd.concat([self.recommendations_df, current_recommendation_df], axis=0)\n",
    "        \n",
    "        # ---- Return ----\n",
    "        return rmse_evaluation\n",
    "    \n",
    "    def cross_validation(self, verbose=True):\n",
    "        \"\"\"\n",
    "        \\ Description:\n",
    "            - Applies Cross-Validation and its results evaluation using RMSE;\n",
    "            - Returns the evaluation as a Pandas DataFrame.\n",
    "        \n",
    "        \\ Parameters:\n",
    "            - Verbose: Boolean.\n",
    "        \"\"\"\n",
    "        # ---- Cross-Validation Step ----\n",
    "        if verbose:\n",
    "            cross_validation_step_title = '** Cross Validation Step **'\n",
    "            print('*' * len(cross_validation_step_title))\n",
    "            print(cross_validation_step_title)\n",
    "            print('*' * len(cross_validation_step_title))\n",
    "            print('---')\n",
    "            \n",
    "        cross_validation_results = cross_validate(self.model, self.full_dataset, n_jobs=-1)\n",
    "        cross_validation_results = round(cross_validation_results['test_rmse'].mean(), 4)\n",
    "            \n",
    "        # ---- Evaluation Step ----\n",
    "        if verbose:\n",
    "            validation_step_title = '** Validation Step **'\n",
    "            print('*' * len(validation_step_title))\n",
    "            print(validation_step_title)\n",
    "            print('*' * len(validation_step_title))\n",
    "        \n",
    "        print(f'- Mean Cross-Validation Root Mean Squared Error (RMSE): {cross_validation_results}')\n",
    "        \n",
    "        # ---- Return ----\n",
    "        return cross_validation_results\n",
    "    \n",
    "    def recommend(self, user_id, n=10, verbose=True):\n",
    "        \"\"\"\n",
    "        \\ Description:\n",
    "            - Gets the 'n' recommended items;\n",
    "            - Returns them as a Pandas DataFrame.\n",
    "        \n",
    "        \\ Parameters:\n",
    "            - User ID: Integer;\n",
    "            - N: Integer;\n",
    "            - Verbose: Boolean.\n",
    "        \"\"\"\n",
    "        # ---- Recommendation Step ----\n",
    "        if verbose:\n",
    "            recommendation_step_title = '** Recommendation Step **'\n",
    "            print('*' * len(recommendation_step_title))\n",
    "            print(recommendation_step_title)\n",
    "            print('*' * len(recommendation_step_title))\n",
    "            print('---')\n",
    "        \n",
    "        recommendations_df = self.recommendations_df.loc[self.recommendations_df['user_id'] == user_id].head(n)\n",
    "        \n",
    "        # ---- Return ----\n",
    "        if verbose: display(recommendations_df)\n",
    "        return recommendations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2a3816-7ca5-4b4b-994b-e5afef38d3d6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**- Reading Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e163072-541b-4bb3-a8f3-917be5d62103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Number of Observations: 23748 (twenty-three thousand, seven hundred and forty-eight)\n",
      "- Number of Variables: 20 (twenty)\n",
      "---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>genres</th>\n",
       "      <th>synopsis</th>\n",
       "      <th>type</th>\n",
       "      <th>episodes</th>\n",
       "      <th>status</th>\n",
       "      <th>producers</th>\n",
       "      <th>licensors</th>\n",
       "      <th>studios</th>\n",
       "      <th>source</th>\n",
       "      <th>duration</th>\n",
       "      <th>rating</th>\n",
       "      <th>rank</th>\n",
       "      <th>popularity</th>\n",
       "      <th>favorites</th>\n",
       "      <th>scored_by</th>\n",
       "      <th>members</th>\n",
       "      <th>image_url</th>\n",
       "      <th>is_hentai</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cowboy bebop</td>\n",
       "      <td>8.75</td>\n",
       "      <td>award winning, action, sci-fi</td>\n",
       "      <td>crime is timeless. by the year 2071, humanity ...</td>\n",
       "      <td>tv</td>\n",
       "      <td>26</td>\n",
       "      <td>finished airing</td>\n",
       "      <td>bandai visual</td>\n",
       "      <td>funimation, bandai entertainment</td>\n",
       "      <td>sunrise</td>\n",
       "      <td>original</td>\n",
       "      <td>24 min per ep</td>\n",
       "      <td>R - 17+ (violence &amp; profanity)</td>\n",
       "      <td>41</td>\n",
       "      <td>43</td>\n",
       "      <td>78525</td>\n",
       "      <td>914193</td>\n",
       "      <td>1771505</td>\n",
       "      <td>https://cdn.myanimelist.net/images/anime/4/196...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cowboy bebop tengoku no tobira</td>\n",
       "      <td>8.38</td>\n",
       "      <td>action, sci-fi</td>\n",
       "      <td>another day, another bounty—such is the life o...</td>\n",
       "      <td>movie</td>\n",
       "      <td>1</td>\n",
       "      <td>finished airing</td>\n",
       "      <td>sunrise, bandai visual</td>\n",
       "      <td>sony pictures entertainment</td>\n",
       "      <td>bones</td>\n",
       "      <td>original</td>\n",
       "      <td>1 hr 55 min</td>\n",
       "      <td>R - 17+ (violence &amp; profanity)</td>\n",
       "      <td>189</td>\n",
       "      <td>602</td>\n",
       "      <td>1448</td>\n",
       "      <td>206248</td>\n",
       "      <td>360978</td>\n",
       "      <td>https://cdn.myanimelist.net/images/anime/1439/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>trigun</td>\n",
       "      <td>8.22</td>\n",
       "      <td>adventure, action, sci-fi</td>\n",
       "      <td>vash the stampede is the man with a $$60,000,0...</td>\n",
       "      <td>tv</td>\n",
       "      <td>26</td>\n",
       "      <td>finished airing</td>\n",
       "      <td>victor entertainment</td>\n",
       "      <td>funimation, geneon entertainment usa</td>\n",
       "      <td>madhouse</td>\n",
       "      <td>manga</td>\n",
       "      <td>24 min per ep</td>\n",
       "      <td>PG-13 - Teens 13 or older</td>\n",
       "      <td>328</td>\n",
       "      <td>246</td>\n",
       "      <td>15035</td>\n",
       "      <td>356739</td>\n",
       "      <td>727252</td>\n",
       "      <td>https://cdn.myanimelist.net/images/anime/7/203...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>witch hunter robin</td>\n",
       "      <td>7.25</td>\n",
       "      <td>mystery, supernatural, action, drama</td>\n",
       "      <td>robin sena is a powerful craft user drafted in...</td>\n",
       "      <td>tv</td>\n",
       "      <td>26</td>\n",
       "      <td>finished airing</td>\n",
       "      <td>dentsu, bandai visual, tv tokyo music, victor ...</td>\n",
       "      <td>funimation, bandai entertainment</td>\n",
       "      <td>sunrise</td>\n",
       "      <td>original</td>\n",
       "      <td>25 min per ep</td>\n",
       "      <td>PG-13 - Teens 13 or older</td>\n",
       "      <td>2764</td>\n",
       "      <td>1795</td>\n",
       "      <td>613</td>\n",
       "      <td>42829</td>\n",
       "      <td>111931</td>\n",
       "      <td>https://cdn.myanimelist.net/images/anime/10/19...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bouken ou beet</td>\n",
       "      <td>6.94</td>\n",
       "      <td>adventure, supernatural, fantasy</td>\n",
       "      <td>it is the dark century and the people are suff...</td>\n",
       "      <td>tv</td>\n",
       "      <td>52</td>\n",
       "      <td>finished airing</td>\n",
       "      <td>dentsu, tv tokyo</td>\n",
       "      <td>illumitoon entertainment</td>\n",
       "      <td>toei animation</td>\n",
       "      <td>manga</td>\n",
       "      <td>23 min per ep</td>\n",
       "      <td>PG - Children</td>\n",
       "      <td>4240</td>\n",
       "      <td>5126</td>\n",
       "      <td>14</td>\n",
       "      <td>6413</td>\n",
       "      <td>15001</td>\n",
       "      <td>https://cdn.myanimelist.net/images/anime/7/215...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title  score  \\\n",
       "id                                          \n",
       "1                     cowboy bebop   8.75   \n",
       "5   cowboy bebop tengoku no tobira   8.38   \n",
       "6                           trigun   8.22   \n",
       "7               witch hunter robin   7.25   \n",
       "8                   bouken ou beet   6.94   \n",
       "\n",
       "                                  genres  \\\n",
       "id                                         \n",
       "1          award winning, action, sci-fi   \n",
       "5                         action, sci-fi   \n",
       "6              adventure, action, sci-fi   \n",
       "7   mystery, supernatural, action, drama   \n",
       "8       adventure, supernatural, fantasy   \n",
       "\n",
       "                                             synopsis   type  episodes  \\\n",
       "id                                                                       \n",
       "1   crime is timeless. by the year 2071, humanity ...     tv        26   \n",
       "5   another day, another bounty—such is the life o...  movie         1   \n",
       "6   vash the stampede is the man with a $$60,000,0...     tv        26   \n",
       "7   robin sena is a powerful craft user drafted in...     tv        26   \n",
       "8   it is the dark century and the people are suff...     tv        52   \n",
       "\n",
       "             status                                          producers  \\\n",
       "id                                                                       \n",
       "1   finished airing                                      bandai visual   \n",
       "5   finished airing                             sunrise, bandai visual   \n",
       "6   finished airing                               victor entertainment   \n",
       "7   finished airing  dentsu, bandai visual, tv tokyo music, victor ...   \n",
       "8   finished airing                                   dentsu, tv tokyo   \n",
       "\n",
       "                               licensors         studios    source  \\\n",
       "id                                                                   \n",
       "1       funimation, bandai entertainment         sunrise  original   \n",
       "5            sony pictures entertainment           bones  original   \n",
       "6   funimation, geneon entertainment usa        madhouse     manga   \n",
       "7       funimation, bandai entertainment         sunrise  original   \n",
       "8               illumitoon entertainment  toei animation     manga   \n",
       "\n",
       "         duration                          rating  rank  popularity  \\\n",
       "id                                                                    \n",
       "1   24 min per ep  R - 17+ (violence & profanity)    41          43   \n",
       "5     1 hr 55 min  R - 17+ (violence & profanity)   189         602   \n",
       "6   24 min per ep       PG-13 - Teens 13 or older   328         246   \n",
       "7   25 min per ep       PG-13 - Teens 13 or older  2764        1795   \n",
       "8   23 min per ep                   PG - Children  4240        5126   \n",
       "\n",
       "    favorites  scored_by  members  \\\n",
       "id                                  \n",
       "1       78525     914193  1771505   \n",
       "5        1448     206248   360978   \n",
       "6       15035     356739   727252   \n",
       "7         613      42829   111931   \n",
       "8          14       6413    15001   \n",
       "\n",
       "                                            image_url  is_hentai  \n",
       "id                                                                \n",
       "1   https://cdn.myanimelist.net/images/anime/4/196...          0  \n",
       "5   https://cdn.myanimelist.net/images/anime/1439/...          0  \n",
       "6   https://cdn.myanimelist.net/images/anime/7/203...          0  \n",
       "7   https://cdn.myanimelist.net/images/anime/10/19...          0  \n",
       "8   https://cdn.myanimelist.net/images/anime/7/215...          0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- Reading Animes Datasets ----\n",
    "animes_df = pd.read_csv(f'{DATASETS_PATH}/anime-transformed-dataset-2023.csv', index_col='id')\n",
    "\n",
    "print(f'- Number of Observations: {animes_df.shape[0]} ({INFLECT_ENGINE.number_to_words(animes_df.shape[0])})')\n",
    "print(f'- Number of Variables: {animes_df.shape[1]} ({INFLECT_ENGINE.number_to_words(animes_df.shape[1])})')\n",
    "print('---')\n",
    "\n",
    "animes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38c0f8a2-9e8b-4bc1-9239-2bf9d71aeb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Number of Observations: 731282 (seven hundred and thirty-one thousand, two hundred and eighty-two)\n",
      "- Number of Variables: 13 (thirteen)\n",
      "---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>joined</th>\n",
       "      <th>days_watched</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>watching</th>\n",
       "      <th>completed</th>\n",
       "      <th>on_hold</th>\n",
       "      <th>dropped</th>\n",
       "      <th>plan_to_watch</th>\n",
       "      <th>total_entries</th>\n",
       "      <th>rewatched</th>\n",
       "      <th>episodes_watched</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xinil</td>\n",
       "      <td>male</td>\n",
       "      <td>2004-11-05t00:00:00+00:00</td>\n",
       "      <td>142.3</td>\n",
       "      <td>7.37</td>\n",
       "      <td>1</td>\n",
       "      <td>233</td>\n",
       "      <td>8</td>\n",
       "      <td>93</td>\n",
       "      <td>64</td>\n",
       "      <td>399</td>\n",
       "      <td>60</td>\n",
       "      <td>8458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aokaado</td>\n",
       "      <td>male</td>\n",
       "      <td>2004-11-11t00:00:00+00:00</td>\n",
       "      <td>68.6</td>\n",
       "      <td>7.34</td>\n",
       "      <td>23</td>\n",
       "      <td>137</td>\n",
       "      <td>99</td>\n",
       "      <td>44</td>\n",
       "      <td>40</td>\n",
       "      <td>343</td>\n",
       "      <td>15</td>\n",
       "      <td>4072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crystal</td>\n",
       "      <td>female</td>\n",
       "      <td>2004-11-13t00:00:00+00:00</td>\n",
       "      <td>212.8</td>\n",
       "      <td>6.68</td>\n",
       "      <td>16</td>\n",
       "      <td>636</td>\n",
       "      <td>303</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>1000</td>\n",
       "      <td>10</td>\n",
       "      <td>12781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>arcane</td>\n",
       "      <td>-</td>\n",
       "      <td>2004-12-05t00:00:00+00:00</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.71</td>\n",
       "      <td>5</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>1817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>mad</td>\n",
       "      <td>-</td>\n",
       "      <td>2005-01-03t00:00:00+00:00</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.27</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>153</td>\n",
       "      <td>42</td>\n",
       "      <td>3038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name  gender                     joined  days_watched  mean_score  \\\n",
       "id                                                                         \n",
       "1     xinil    male  2004-11-05t00:00:00+00:00         142.3        7.37   \n",
       "3   aokaado    male  2004-11-11t00:00:00+00:00          68.6        7.34   \n",
       "4   crystal  female  2004-11-13t00:00:00+00:00         212.8        6.68   \n",
       "9    arcane       -  2004-12-05t00:00:00+00:00          30.0        7.71   \n",
       "18      mad       -  2005-01-03t00:00:00+00:00          52.0        6.27   \n",
       "\n",
       "    watching  completed  on_hold  dropped  plan_to_watch  total_entries  \\\n",
       "id                                                                        \n",
       "1          1        233        8       93             64            399   \n",
       "3         23        137       99       44             40            343   \n",
       "4         16        636      303        0             45           1000   \n",
       "9          5         54        4        3              0             66   \n",
       "18         1        114       10        5             23            153   \n",
       "\n",
       "    rewatched  episodes_watched  \n",
       "id                               \n",
       "1          60              8458  \n",
       "3          15              4072  \n",
       "4          10             12781  \n",
       "9           0              1817  \n",
       "18         42              3038  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- Reading Users Dataset ----\n",
    "users_df = pd.read_csv(f'{DATASETS_PATH}/users-details-transformed-2023.csv', index_col='id')\n",
    "\n",
    "print(f'- Number of Observations: {users_df.shape[0]} ({INFLECT_ENGINE.number_to_words(users_df.shape[0])})')\n",
    "print(f'- Number of Variables: {users_df.shape[1]} ({INFLECT_ENGINE.number_to_words(users_df.shape[1])})')\n",
    "print('---')\n",
    "\n",
    "users_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eea99b2-6e52-4f53-9dc7-34e2b2da11f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Number of Observations: 23796586 (twenty-three million, seven hundred and ninety-six thousand, five hundred and eighty-six)\n",
      "- Number of Variables: 5 (five)\n",
      "---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>anime_title</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>xinil</td>\n",
       "      <td>21</td>\n",
       "      <td>one piece</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>xinil</td>\n",
       "      <td>48</td>\n",
       "      <td>hack sign</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>xinil</td>\n",
       "      <td>320</td>\n",
       "      <td>a kite</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>xinil</td>\n",
       "      <td>49</td>\n",
       "      <td>aa megami-sama</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>xinil</td>\n",
       "      <td>304</td>\n",
       "      <td>aa megami-sama movie</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id username  anime_id           anime_title  rating\n",
       "0        1    xinil        21             one piece       9\n",
       "1        1    xinil        48             hack sign       7\n",
       "2        1    xinil       320                a kite       5\n",
       "3        1    xinil        49        aa megami-sama       8\n",
       "4        1    xinil       304  aa megami-sama movie       8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- Reading Ratings Dataset ----\n",
    "ratings_df = pd.read_csv(f'{DATASETS_PATH}/users-scores-transformed-2023.csv')\n",
    "\n",
    "print(f'- Number of Observations: {ratings_df.shape[0]} ({INFLECT_ENGINE.number_to_words(ratings_df.shape[0])})')\n",
    "print(f'- Number of Variables: {ratings_df.shape[1]} ({INFLECT_ENGINE.number_to_words(ratings_df.shape[1])})')\n",
    "print('---')\n",
    "\n",
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f60f928-d81e-4fc8-b20b-d0ad2f55c146",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**- Dropping Variables**\n",
    "\n",
    "For Surprise package, only three variables are needed: the user id, the anime id and the rating the user gave to the anime. Thus, we have to drop the user name and anime title variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "090c28b3-991b-4cd2-86ec-be832877940b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Dropping Variables ----\n",
    "variables_to_keep = ['user_id', 'anime_id', 'rating']\n",
    "ratings_df = ratings_df[variables_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173d4dc4-9c9d-4c0f-a954-0b4b5c15e6af",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**- Getting Random Observations for Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "248125b5-035a-4edf-ab01-d938def9491b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Number of Observations for Hyperparameter Tuning: 10000 (ten thousand)\n",
      "---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19605608</th>\n",
       "      <td>801693</td>\n",
       "      <td>121</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13309570</th>\n",
       "      <td>419973</td>\n",
       "      <td>400</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22818381</th>\n",
       "      <td>1210695</td>\n",
       "      <td>20583</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16231934</th>\n",
       "      <td>488043</td>\n",
       "      <td>22729</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13080137</th>\n",
       "      <td>414120</td>\n",
       "      <td>4898</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  anime_id  rating\n",
       "19605608   801693       121       5\n",
       "13309570   419973       400       4\n",
       "22818381  1210695     20583       8\n",
       "16231934   488043     22729       3\n",
       "13080137   414120      4898       9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- Getting Random Observations for Hyperparameter Tuning ----\n",
    "hyperparameter_tuning_df = ratings_df.sample(HYPERPARAMETER_TUNING_SAMPLE_SIZE, random_state=SEED)\n",
    "hyperparameter_tuning_surprise_df = Dataset.load_from_df(hyperparameter_tuning_df, SURPRISE_READER)\n",
    "\n",
    "print(\n",
    "    f'- Number of Observations for Hyperparameter Tuning: {HYPERPARAMETER_TUNING_SAMPLE_SIZE}'\n",
    "    f' ({INFLECT_ENGINE.number_to_words(HYPERPARAMETER_TUNING_SAMPLE_SIZE)})'\n",
    ")\n",
    "print('---')\n",
    "\n",
    "hyperparameter_tuning_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b62e56-2828-4914-9d83-b4e8fb1a1501",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**- Finding Best Hyperparameters for the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd45fd2d-b039-40c6-b142-e412676ffd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Best Score: {'rmse': 3.1168631630307444}\n",
      "- Best Parameters: {'rmse': {'k': 30, 'min_k': 25, 'sim_options': {'name': 'pearson_baseline', 'user_based': True, 'min_support': 5}}}\n",
      "- Best Estimator: {'rmse': <surprise.prediction_algorithms.knns.KNNWithMeans object at 0x00000140FF525E10>}\n"
     ]
    }
   ],
   "source": [
    "# ---- Finding the Best Hyperparameters for the Model ----\n",
    "#\n",
    "# - using Randomized Search CV in order to find the best Hyperparameters Values.\n",
    "#\n",
    "hyperparameters_tuning_values = find_best_hyperparameters_values(\n",
    "    model=KNNWithMeans\n",
    "    , search_cv=RandomizedSearchCV\n",
    "    , parameters=KNN_PARAMS\n",
    "    , dataset=hyperparameter_tuning_surprise_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cdbaa73-73e5-445f-9224-62b9058ac953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Finding Best Hyperparameters for the Model ----\n",
    "#\n",
    "# - getting the model with the best parameters.\n",
    "#\n",
    "chosen_knn_with_means_model = hyperparameters_tuning_values.best_estimator['rmse']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8b210a-d9f8-4bf0-9b0f-a6fb48492a1a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**- Splitting Dataset into Training and Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd48dadb-715d-49e9-993d-ba38c80c8a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Splitting Dataset into Training and Validation ----\n",
    "#\n",
    "# - converting Pandas DataFrame into Surprise DataFrame\n",
    "#\n",
    "ratings_surprise_df = Dataset.load_from_df(ratings_df, SURPRISE_READER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbba1bb0-0d25-4e75-aa6a-537f17f966a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Splitting Dataset into Training and Validation ----\n",
    "#\n",
    "# - deleting some datafra,es from the memory since we are going to use 'ratings_surprise_df' from now on;\n",
    "# - datasets to delete:\n",
    "#    \\ ratings_df;\n",
    "#    \\ hyperparameter_tuning_df;\n",
    "#    \\ hyperparameter_tuning_surprise_df.\n",
    "#\n",
    "ratings_df = None\n",
    "hyperparameter_tuning_df = None\n",
    "hyperparameter_tuning_surprise_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "148d6210-b5a3-4b12-9bb4-79d3eb61b3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Splitting Dataset into Trainig and Validation ----\n",
    "#\n",
    "# - training: 80%\n",
    "# - validation: 20%\n",
    "#\n",
    "training_surprise_df, validation_surprise_df = train_test_split(\n",
    "    data=ratings_surprise_df\n",
    "    , train_size=TRAINING_DF_SIZE\n",
    "    , test_size=VALIDATION_DF_SIZE\n",
    "    , random_state=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a8cc5d-4ec6-45b0-81a8-d10dd739ce30",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**- Training the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b59edaa-3d76-4f26-a961-2ed47e16a77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************\n",
      "** Fitting Step **\n",
      "******************\n",
      "---\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 250. GiB for an array with shape (259076, 259076) and data type int32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 14\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ---- Training the Model ----\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# - creating the model;\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# - fitting and predicting;\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# - cross-validating datas.\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      7\u001b[0m user_based_recommender \u001b[38;5;241m=\u001b[39m collaborative_filtering_user_based_approach(\n\u001b[0;32m      8\u001b[0m     chosen_knn_with_means_model\n\u001b[0;32m      9\u001b[0m     , training_surprise_df\n\u001b[0;32m     10\u001b[0m     , validation_surprise_df\n\u001b[0;32m     11\u001b[0m     , ratings_surprise_df\n\u001b[0;32m     12\u001b[0m )\n\u001b[1;32m---> 14\u001b[0m model_rmse \u001b[38;5;241m=\u001b[39m \u001b[43muser_based_recommender\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_and_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m modedl_cross_validation_rmse \u001b[38;5;241m=\u001b[39m user_based_recommender\u001b[38;5;241m.\u001b[39mcross_validate(verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[9], line 167\u001b[0m, in \u001b[0;36mcollaborative_filtering_user_based_approach.fit_and_predict\u001b[1;34m(self, verbose)\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(fitting_step_title))\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m---\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 167\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;66;03m# ---- Validation Step -----\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\surprise\\prediction_algorithms\\knns.py:176\u001b[0m, in \u001b[0;36mKNNWithMeans.fit\u001b[1;34m(self, trainset)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainset):\n\u001b[0;32m    175\u001b[0m     SymmetricAlgo\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;28mself\u001b[39m, trainset)\n\u001b[1;32m--> 176\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_similarities\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeans \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_x)\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x, ratings \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxr\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\surprise\\prediction_algorithms\\algo_base.py:248\u001b[0m, in \u001b[0;36mAlgoBase.compute_similarities\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m similarity matrix...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 248\u001b[0m sim \u001b[38;5;241m=\u001b[39m \u001b[43mconstruction_func\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone computing similarity matrix.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\surprise\\similarities.pyx:289\u001b[0m, in \u001b[0;36msurprise.similarities.pearson_baseline\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 250. GiB for an array with shape (259076, 259076) and data type int32"
     ]
    }
   ],
   "source": [
    "# ---- Training the Model ----\n",
    "#\n",
    "# - creating the model;\n",
    "# - fitting and predicting;\n",
    "# - cross-validating datas.\n",
    "#\n",
    "user_based_recommender = collaborative_filtering_user_based_approach(\n",
    "    chosen_knn_with_means_model\n",
    "    , training_surprise_df\n",
    "    , validation_surprise_df\n",
    "    , ratings_surprise_df\n",
    ")\n",
    "\n",
    "model_rmse = user_based_recommender.fit_and_predict(verbose=True)\n",
    "model_cross_validation_rmse = user_based_recommender.cross_validate(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30aa432-4091-43af-ac31-c1f5fb77f40a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**- Recommendations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44211a7-216f-4346-a334-a91ab23029ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Recommendations ----\n",
    "user_based_top_10_animes = collaborative_filtering_user_based_recommender.recommend(user_id=1, n=10, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d403658-2c19-4e8e-8c48-4efe785daaa7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h1 id='reach-me' style='color:#7159c1; border-bottom:3px solid #7159c1; letter-spacing:2px; font-family:JetBrains Mono; font-weight: bold; text-align:left; font-size:240%;padding:0'>📫 | Reach Me</h1>\n",
    "\n",
    "> **Email** - [csfelix08@gmail.com](mailto:csfelix08@gmail.com?)\n",
    "\n",
    "> **Linkedin** - [linkedin.com/in/csfelix/](https://www.linkedin.com/in/csfelix/)\n",
    "\n",
    "> **GitHub:** - [CSFelix](https://github.com/CSFelix)\n",
    "\n",
    "> **Kaggle** - [DSFelix](https://www.kaggle.com/dsfelix)\n",
    "\n",
    "> **Portfolio** - [CSFelix.io](https://csfelix.github.io/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

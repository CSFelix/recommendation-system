{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f46bb15-dc34-4297-bfc3-2d721bc75a52",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1 id='content-based-filtering' style='color:#7159c1; font-size:350%'>Collaborative Filtering</h1>\n",
    "    <i style='font-size:125%'>Recommendations of Items from Similar Items that Similar Users Liked</i>\n",
    "</center>\n",
    "\n",
    "> **Topics**\n",
    "\n",
    "```\n",
    "- ‚ú® Collaborative Filtering User-Based Problems\n",
    "- ‚ú® Item-Based Approach\n",
    "- ‚ú® Matrix Decomposition\n",
    "- ‚ú® Singular Value Decomposition (SVD)\n",
    "- ‚ú® Singular Value Decomposition (SVD) VS Singular Value Decomposition Plus (SVD++)\n",
    "- ‚ú® Hands-on\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7188abe0-7a59-4969-974a-4259eb35154e",
   "metadata": {},
   "source": [
    "<h1 id='0-collaborative-user-based-problems' style='color:#7159c1; border-bottom:3px solid #7159c1; letter-spacing:2px; font-family:JetBrains Mono; font-weight: bold; text-align:left; font-size:240%;padding:0'>‚ú® | Collaborative Filtering User-Based Problems</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb99355-1797-461a-a8c9-fbc4bd3c194a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5073ff7-384a-4396-a204-39cdaa27fe3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9475b8-55ce-4a80-b631-4ae9227a9c57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0006659-5bf1-44c5-ab72-59f4a308910c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deab49d7-1108-4c4a-9156-ba7912f02d47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d19565f-3390-44cf-9b1e-43369a9fab71",
   "metadata": {},
   "source": [
    "<h1 id='5-hands-on' style='color:#7159c1; border-bottom:3px solid #7159c1; letter-spacing:2px; font-family:JetBrains Mono; font-weight: bold; text-align:left; font-size:240%;padding:0'>‚ú® | Hands-on</h1>\n",
    "\n",
    "```\n",
    "- Settings\n",
    "- Reading Datasets\n",
    "- Dropping Variables\n",
    "- Getting Random Observations for Hyperparameter Tuning\n",
    "- Finding Best Hyperparameters for the Model\n",
    "- Splitting Dataset into Training and Validation\n",
    "- Training the Model\n",
    "- Recommendations\n",
    "```\n",
    "\n",
    "> **OBS.:** since Surprise Package only works with ratings from 0 to 5 and the animes dataset works with ratings from 0 to 10, we have to divide the animes dataset ratings by 2 in order to the Surprise Predictions be accordingly to the range from 0 to 5. After that, we have to multiply the Surprise Predictions by 2 in order to the predictions fit the animes dataset ratings when returning the recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec15c64-5e1c-4e78-9ab9-98f593db0ddc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**- Settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bde7e2be-c1f4-4872-a561-29c2cf673565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------\n",
    "# ---- Imports ----\n",
    "# -----------------\n",
    "from collections import defaultdict  # pip install collections\n",
    "import inflect                       # pip install inflect\n",
    "import numpy as np                   # pip install numpy\n",
    "import pandas as pd                  # pip install pandas\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# ---- Surprise Imports ----\n",
    "# --------------------------\n",
    "#\n",
    "# pip install scikit-surprise\n",
    "#\n",
    "# If you get any troubles installing the package, follow the steps in this Stack Overflow link:\n",
    "# - https://stackoverflow.com/questions/44951456/pip-error-microsoft-visual-c-14-0-is-required\n",
    "#\n",
    "from surprise import accuracy\n",
    "from surprise import SVD\n",
    "from surprise.dataset import Dataset\n",
    "from surprise.model_selection.validation import cross_validate\n",
    "from surprise.model_selection import RandomizedSearchCV\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.reader import Reader\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -------------------\n",
    "# ---- Constants ----\n",
    "# -------------------\n",
    "DATASETS_PATH = ('./datasets')\n",
    "INFLECT_ENGINE = (inflect.engine())\n",
    "SEED = (20240106)\n",
    "SEED2 = (20240107)\n",
    "SURPRISE_READER = (Reader())\n",
    "\n",
    "HYPERPARAMETER_TUNING_SAMPLE_SIZE = 250_000 # SVD has a better memory performance than KNN, thus we can increase the sample size\n",
    "# however, with more than 250,000 observations, the training and prediction steps take a considerable time\n",
    "TRAINING_DF_SIZE = (0.80)\n",
    "VALIDATION_DF_SIZE = (0.20)\n",
    "\n",
    "SIMILARITY_OPTIONS = {\n",
    "    'name': ['cosine', 'pearson', 'pearson_baseline', 'msd'] # similarity metrics: the best one will be used for recommendations;\n",
    "    , 'user_based': [False] # True: User-Based Approach; False: Item-Based Approach;\n",
    "    , 'min_support': [3, 4, 5] # User-Based: minimum number of similar items to be considered; item-Based: minimum number of similar users to be considedred.\n",
    "}\n",
    "SVD_PARAMS = {\n",
    "    'n_epochs': [5, 10, 15, 20] # number of iterations in SVD;\n",
    "    , 'lr_all': [0.002, 0.005, 0.007]  # learning rate for all parameters (lr_bu, lr_bi, lr_pu and lr_qi);\n",
    "    , 'reg_all': [0.4, 0.6, 0.8] # regularization term for all parameters (reg_bu, reg_bi, reg_pu and reg_qi).\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ------------------\n",
    "# ---- Settings ----\n",
    "# ------------------\n",
    "np.random.seed(SEED)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -------------------\n",
    "# ---- Functions ----\n",
    "# -------------------\n",
    "def find_best_hyperparameters_values(model, search_cv, parameters, dataset):\n",
    "    \"\"\"\n",
    "    \\ Description:\n",
    "        - Creates a parameter Search CV to find the best score, hyperparameters values and estimators for a given\n",
    "    Singular Value Decomposition model;\n",
    "        - Returns the best model and its score, hyperparameters and estimators.\n",
    "        \n",
    "    \\ Parameters:\n",
    "        - model: Chosen Matrix Decomposition Model. For this notebook, Singular Value Decomposition (SVD) is the chosen one;\n",
    "        - search-cv: Surprise Parameter Search. For this notebook, Randomized Search CV is the chosen one;\n",
    "        - parameters: dictionary of SVD Parameters;\n",
    "        - dataset: Surprise DataFrame.\n",
    "    \"\"\"\n",
    "    matrix_decomposition_model = search_cv(\n",
    "        model\n",
    "        , parameters\n",
    "        , n_jobs=-1                 # number of CPU cores used opn models' training and validation (-1 all cores are user)\n",
    "        , measures=['rmse']         # evaluation metrics\n",
    "        , cv=3                      # number of folds for cross-validation\n",
    "        , pre_dispatch='1*n_jobs'   # number of dispatches for each job to process simultaneously\n",
    "        , random_state=SEED\n",
    "    )\n",
    "    matrix_decomposition_model.fit(dataset)\n",
    "    \n",
    "    print(f'- Best Score: {matrix_decomposition_model.best_score}')\n",
    "    print(f'- Best Parameters: {matrix_decomposition_model.best_params}')\n",
    "    print(f'- Best Estimator: {matrix_decomposition_model.best_estimator}')\n",
    "    \n",
    "    return matrix_decomposition_model\n",
    "\n",
    "def get_recommendations(predictions_df, animes_df, maximum_number_of_recommendations=10):\n",
    "    \"\"\"\n",
    "    \\ Description:\n",
    "        - Maps the Predictions for Each User;\n",
    "        - Sorts the Predictions for Each User;\n",
    "        - Creates a List Containing the 'maximum_number_of_recommendations';\n",
    "        - Returns the List.\n",
    "        \n",
    "    \\ Parameters:\n",
    "        - Predictions DF: Surprise DataFrame;\n",
    "        - Animes DF: Pandas DataFrame;\n",
    "        - Maximum Number of Recommendations: Integer.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Mapping the Predictions for Each User\n",
    "    #\n",
    "    # - since Surprise Package only works with ratings from 0 to 5 and\n",
    "    # the animes dataset works with ratings from 0 to 10, we have to\n",
    "    # multiply the 'estimated (est)' value by 2, in order to the Surprise\n",
    "    # predictions fit into the animes dataset ratings.\n",
    "    #\n",
    "    top_n_recommendations = defaultdict(list)\n",
    "    for uuid, id, true_r, est, _ in predictions_df: top_n_recommendations[uuid].append((id, est * 2))\n",
    "    \n",
    "    # Sorting Predictions for Each User and Retrieving the Recommendations\n",
    "    for uuid, user_ratings in top_n_recommendations.items():\n",
    "        user_ratings.sort(key=lambda rating: rating[1], reverse=True)\n",
    "        top_n_recommendations[uuid] = user_ratings[:maximum_number_of_recommendations]\n",
    "        \n",
    "    return top_n_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f751a1c8-6dc0-46cc-8840-438127fbb340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------\n",
    "# ---- Classes ----\n",
    "# -----------------\n",
    "class collaborative_filtering_item_based_approach():\n",
    "    \"\"\"\n",
    "    This class apply Collaborative Filtering with Item-Based Approach to recommend 'n' animes to a given user.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, training_df, validation_df, full_dataset, animes_df):\n",
    "        \"\"\"\n",
    "        \\ Description:\n",
    "            - Class Constructor.\n",
    "            \n",
    "        \\ Parameters:\n",
    "            - Model: Surprise Prediction Model. Singular Value Decomposition is the chosen one for this notebook;\n",
    "            - Training DF: Surprise DataFrame;\n",
    "            - Validation DF: Surprise DataFrame;\n",
    "            - Full Dataset: Surprise DataFrame (Merge of: Training DF and Validation DF);\n",
    "            - Animes DF: Pandas DataFrame.\n",
    "            \n",
    "        \\ Other Attributes:\n",
    "            - Predictions Validations: Surprise DataFrame;\n",
    "            - Top Recommendations: Surprise DataFrame;\n",
    "            - Recommendations DF: Pandas DataFrame.\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.training_df = training_df\n",
    "        self.validation_df = validation_df\n",
    "        self.full_dataset = full_dataset\n",
    "        self.animes_df = animes_df\n",
    "        \n",
    "        self.predictions_validations = None\n",
    "        self.top_recommendations = None\n",
    "        self.recommendations_df = None\n",
    "        \n",
    "    def fit_and_predict(self, maximum_number_of_recommendations, verbose=True):\n",
    "        \"\"\"\n",
    "        \\ Description:\n",
    "            - Applies training, validation and evaluation steps;\n",
    "            - Gets the top 'n' recommendations;\n",
    "            - Returns the top 'n' recommendations as a Pandas DataFrame.\n",
    "            \n",
    "        \\ Parameters:\n",
    "            - Maximum Number of Recommendations: Integer;\n",
    "            - Verbose: Boolean.\n",
    "        \"\"\"\n",
    "        # ---- Fitting Step ----\n",
    "        if verbose:\n",
    "            fitting_step_title = '** Fitting Step **'\n",
    "            print('*' * len(fitting_step_title))\n",
    "            print(fitting_step_title)\n",
    "            print('*' * len(fitting_step_title))\n",
    "            print('\\n')\n",
    "        \n",
    "        self.model.fit(self.training_df)\n",
    "        \n",
    "        # ---- Prediction Step ----\n",
    "        if verbose:\n",
    "            prediction_step_title = '** Prediction Step **'\n",
    "            print('\\n\\n')\n",
    "            print('*' * len(prediction_step_title))\n",
    "            print(prediction_step_title)\n",
    "            print('*' * len(prediction_step_title))\n",
    "            print('\\n')\n",
    "            \n",
    "        self.predictions_validations = self.model.test(self.validation_df)\n",
    "        \n",
    "        # ---- Evaluation Step ----\n",
    "        if verbose:\n",
    "            evaluation_step_title = '** Evaluation Step **'\n",
    "            print('\\n\\n')\n",
    "            print('*' * len(evaluation_step_title))\n",
    "            print(evaluation_step_title)\n",
    "            print('*' * len(evaluation_step_title))\n",
    "            print('\\n')\n",
    "            \n",
    "        rmse_evaluation = round(accuracy.rmse(self.predictions_validations), 4)\n",
    "        print(f'- Root Mean Squared Error (RMSE) for the predictions: {rmse_evaluation}')\n",
    "        print('\\n\\n')\n",
    "        \n",
    "        # ---- Getting Recommendations ----\n",
    "        if verbose:\n",
    "            predicting_recommendations_step_title = '** Predicting Recommendations Step **'\n",
    "            print('\\n\\n')\n",
    "            print('*' * len(predicting_recommendations_step_title))\n",
    "            print(predicting_recommendations_step_title)\n",
    "            print('*' * len(predicting_recommendations_step_title))\n",
    "            print('\\n')\n",
    "            \n",
    "        self.top_recommendations = get_recommendations(self.predictions_validations, self.animes_df)\n",
    "        self.recommendations_df = pd.DataFrame(columns=['user_id', 'anime_id', 'predicted_rating'])\n",
    "        \n",
    "        for item in self.top_recommendations:\n",
    "            current_recommendation_df = pd.DataFrame(self.top_recommendations[item], columns=['anime_id', 'predicted_rating'])\n",
    "            current_recommendation_df['user_id'] = item\n",
    "            recommendation_variables = current_recommendation_df.columns.tolist()\n",
    "            recommendation_variables = recommendation_variables[-1:] + recommendation_variables[:-1]\n",
    "            current_recommendation_df = current_recommendation_df[recommendation_variables]\n",
    "            self.recommendations_df = pd.concat([self.recommendations_df, current_recommendation_df], axis=0)\n",
    "            \n",
    "        # ---- Return ----\n",
    "        print('Fitting and Prediction Done üòâüëç')\n",
    "        print('\\n')\n",
    "        return rmse_evaluation\n",
    "    \n",
    "    def cross_validation(self, verbose=True):\n",
    "        \"\"\"\n",
    "        \\ Description:\n",
    "            - Applies Cross-Validation and its results evaluation using RMSE;\n",
    "            - Returns the evaluation as a Pandas DataFrame.\n",
    "            \n",
    "        \\ Parameters:\n",
    "            - Verbose: Boolean.\n",
    "        \"\"\"\n",
    "        # ---- Cross-Validation Step ----\n",
    "        if verbose:\n",
    "            cross_validation_step_title = '** Cross-Validation Step **'\n",
    "            print('*' * len(cross_validation_step_title))\n",
    "            print(cross_validation_step_title)\n",
    "            print('*' * len(cross_validation_step_title))\n",
    "            print('\\n')\n",
    "            \n",
    "        cross_validation_results = cross_validate(self.model, self.full_dataset, n_jobs=-1)\n",
    "        cross_validation_results = round(cross_validation_results['test_rmse'].mean(), 4)\n",
    "        \n",
    "        # ---- Evaluation Step ----\n",
    "        if verbose:\n",
    "            validation_step_title = '** Validation Step **'\n",
    "            print('\\n\\n')\n",
    "            print('*' * len(validation_step_title))\n",
    "            print(validation_step_title)\n",
    "            print('*' * len(validation_step_title))\n",
    "            print('\\n')\n",
    "            \n",
    "        print(f'- Mean Cross-Validation Root Mean Squared Error (RMSE): {cross_validation_results}')\n",
    "        print('\\n\\n')\n",
    "        \n",
    "        # ---- Return ----\n",
    "        print('Cross-Validation Done üòâüëç')\n",
    "        print('\\n')\n",
    "        return cross_validation_results\n",
    "    \n",
    "    def recommend(self, user_id, maximum_number_of_recommendations=10, verbose=True):\n",
    "        \"\"\"\n",
    "        \\ Description:\n",
    "            - Gets the 'n' recommended items;\n",
    "            - Gets the recommeded animes info;\n",
    "            - Returns the recommended animes info and the predicted rating as a Pandas DataFrame.\n",
    "            \n",
    "        \\ Parameters:\n",
    "            - User ID: Integer;\n",
    "            - Maximum Number of Recommendations: Integer;\n",
    "            - Verbose: Boolean.\n",
    "        \"\"\"\n",
    "        # ---- Recommendation Step ----\n",
    "        if verbose:\n",
    "            recommendation_step_title = '** Recommendations Step **'\n",
    "            print('*' * len(recommendation_step_title))\n",
    "            print(recommendation_step_title)\n",
    "            print('*' * len(recommendation_step_title))\n",
    "            print('\\n')\n",
    "            \n",
    "        recommendations_df = self.recommendations_df.loc[self.recommendations_df['user_id'] == user_id] \\\n",
    "            .head(maximum_number_of_recommendations)\n",
    "        \n",
    "        # Formatting Animes Recommendation DataFrame ----\n",
    "        recommended_anime_ids = recommendations_df.anime_id.to_list()\n",
    "        recommended_animes_df = self.animes_df.loc[recommended_anime_ids]\n",
    "        recommended_animes_df['predicted_rating'] = recommendations_df['predicted_rating'].to_list()\n",
    "        \n",
    "        # ---- Return ----\n",
    "        if verbose: display(recommended_animes_df)\n",
    "        print('Recommendations Done, Enjoy üòâüëç')\n",
    "        print('\\n')\n",
    "        \n",
    "        return recommended_animes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b28b851-c040-42bb-9fc6-2d69834f98e2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**- Reading Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1403beb0-a5d3-4598-a586-360fe289c14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Number of Observations: 23748 (twenty-three thousand, seven hundred and forty-eight)\n",
      "- Number of Variables: 5 (five)\n",
      "---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>genres</th>\n",
       "      <th>is_hentai</th>\n",
       "      <th>image_url</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cowboy bebop</td>\n",
       "      <td>8.75</td>\n",
       "      <td>award winning, action, sci-fi</td>\n",
       "      <td>0</td>\n",
       "      <td>https://cdn.myanimelist.net/images/anime/4/19644.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cowboy bebop tengoku no tobira</td>\n",
       "      <td>8.38</td>\n",
       "      <td>action, sci-fi</td>\n",
       "      <td>0</td>\n",
       "      <td>https://cdn.myanimelist.net/images/anime/1439/93480.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>trigun</td>\n",
       "      <td>8.22</td>\n",
       "      <td>adventure, action, sci-fi</td>\n",
       "      <td>0</td>\n",
       "      <td>https://cdn.myanimelist.net/images/anime/7/20310.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>witch hunter robin</td>\n",
       "      <td>7.25</td>\n",
       "      <td>mystery, supernatural, action, drama</td>\n",
       "      <td>0</td>\n",
       "      <td>https://cdn.myanimelist.net/images/anime/10/19969.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bouken ou beet</td>\n",
       "      <td>6.94</td>\n",
       "      <td>adventure, supernatural, fantasy</td>\n",
       "      <td>0</td>\n",
       "      <td>https://cdn.myanimelist.net/images/anime/7/21569.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title  score  \\\n",
       "id                                          \n",
       "1                     cowboy bebop   8.75   \n",
       "5   cowboy bebop tengoku no tobira   8.38   \n",
       "6                           trigun   8.22   \n",
       "7               witch hunter robin   7.25   \n",
       "8                   bouken ou beet   6.94   \n",
       "\n",
       "                                  genres  is_hentai  \\\n",
       "id                                                    \n",
       "1          award winning, action, sci-fi          0   \n",
       "5                         action, sci-fi          0   \n",
       "6              adventure, action, sci-fi          0   \n",
       "7   mystery, supernatural, action, drama          0   \n",
       "8       adventure, supernatural, fantasy          0   \n",
       "\n",
       "                                                  image_url  \n",
       "id                                                           \n",
       "1      https://cdn.myanimelist.net/images/anime/4/19644.jpg  \n",
       "5   https://cdn.myanimelist.net/images/anime/1439/93480.jpg  \n",
       "6      https://cdn.myanimelist.net/images/anime/7/20310.jpg  \n",
       "7     https://cdn.myanimelist.net/images/anime/10/19969.jpg  \n",
       "8      https://cdn.myanimelist.net/images/anime/7/21569.jpg  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- Reading Animes Dataset ----\n",
    "animes_df = pd.read_csv(f'{DATASETS_PATH}/anime-transformed-dataset-2023.csv', index_col='id')[\n",
    "    ['title', 'score', 'genres', 'is_hentai', 'image_url']\n",
    "]\n",
    "\n",
    "print(f'- Number of Observations: {animes_df.shape[0]} ({INFLECT_ENGINE.number_to_words(animes_df.shape[0])})')\n",
    "print(f'- Number of Variables: {animes_df.shape[1]} ({INFLECT_ENGINE.number_to_words(animes_df.shape[1])})')\n",
    "print('---')\n",
    "\n",
    "animes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f90c293-da15-4f52-9b5b-1c35182bf2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Number of Observations: 23796586 (twenty-three million, seven hundred and ninety-six thousand, five hundred and eighty-six)\n",
      "- Number of Variables: 5 (five)\n",
      "---\n",
      "- Number of Unique Users: 264067 (two hundred and sixty-four thousand and sixty-seven)\n",
      "- Number of Unique Animes: 16380 (sixteen thousand, three hundred and eighty)\n",
      "---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>anime_title</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>xinil</td>\n",
       "      <td>21</td>\n",
       "      <td>one piece</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>xinil</td>\n",
       "      <td>48</td>\n",
       "      <td>hack sign</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>xinil</td>\n",
       "      <td>320</td>\n",
       "      <td>a kite</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>xinil</td>\n",
       "      <td>49</td>\n",
       "      <td>aa megami-sama</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>xinil</td>\n",
       "      <td>304</td>\n",
       "      <td>aa megami-sama movie</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id username  anime_id           anime_title  rating\n",
       "0        1    xinil        21             one piece       9\n",
       "1        1    xinil        48             hack sign       7\n",
       "2        1    xinil       320                a kite       5\n",
       "3        1    xinil        49        aa megami-sama       8\n",
       "4        1    xinil       304  aa megami-sama movie       8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- Reading Ratings Dataset ----\n",
    "ratings_df = pd.read_csv(f'{DATASETS_PATH}/users-scores-transformed-2023.csv')\n",
    "\n",
    "print(f'- Number of Observations: {ratings_df.shape[0]} ({INFLECT_ENGINE.number_to_words(ratings_df.shape[0])})')\n",
    "print(f'- Number of Variables: {ratings_df.shape[1]} ({INFLECT_ENGINE.number_to_words(ratings_df.shape[1])})')\n",
    "print('---')\n",
    "\n",
    "print(f'- Number of Unique Users: {ratings_df.user_id.nunique()} ({INFLECT_ENGINE.number_to_words(ratings_df.user_id.nunique())})')\n",
    "print(f'- Number of Unique Animes: {ratings_df.anime_id.nunique()} ({INFLECT_ENGINE.number_to_words(ratings_df.anime_id.nunique())})')\n",
    "print('---')\n",
    "\n",
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39730c99-fd41-4389-8585-a295be86ae18",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**- Dropping Variables**\n",
    "\n",
    "For Surprise package, only three variables are needed: the user id, the anime id and the rating the user gave to the anime. Thus, we have to drop the user name and anime title variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b86e7081-5a44-4ebc-81ea-f0cbc7d139d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Dropping Variables ----\n",
    "variables_to_keep = ['user_id', 'anime_id', 'rating']\n",
    "ratings_df = ratings_df[variables_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2df0839-af9f-4874-a5e5-f20b117fbdb0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**- Getting Random Observations for Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32844c23-167c-41e3-9541-5484613d7744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Number of Observations for Hyperparameter Tuning: 250000 (two hundred and fifty thousand)\n"
     ]
    }
   ],
   "source": [
    "# ---- Getting Random Observations for Hyperparameter Tuning ----\n",
    "#\n",
    "# - since Surprise Package only works with ratings from 0 to 5 and\n",
    "# the animes dataset works with ratings from 0 to 10, we have to\n",
    "# divide the 'rating' variable by 2, in order to the anime dataset\n",
    "# ratings fit into Surprise Predictions.\n",
    "#\n",
    "temp_ratings_df = ratings_df.copy()\n",
    "temp_ratings_df.rating = temp_ratings_df.rating.apply(lambda rating: rating / 2)\n",
    "\n",
    "hyperparameter_tuning_df = temp_ratings_df.sample(HYPERPARAMETER_TUNING_SAMPLE_SIZE, random_state=SEED)\n",
    "hyperparameter_tuning_df = Dataset.load_from_df(hyperparameter_tuning_df, SURPRISE_READER)\n",
    "\n",
    "print(\n",
    "    f'- Number of Observations for Hyperparameter Tuning: {HYPERPARAMETER_TUNING_SAMPLE_SIZE}'\n",
    "    f' ({INFLECT_ENGINE.number_to_words(HYPERPARAMETER_TUNING_SAMPLE_SIZE)})'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7951ca61-bbb2-4679-a2d0-f3a56d9bbb53",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**- Finding Best Hyperparameters for the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "932d4aec-0ff1-4170-9b63-0af91f3c9fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Best Score: {'rmse': 0.7450818977744432}\n",
      "- Best Parameters: {'rmse': {'n_epochs': 20, 'lr_all': 0.007, 'reg_all': 0.4}}\n",
      "- Best Estimator: {'rmse': <surprise.prediction_algorithms.matrix_factorization.SVD object at 0x0000021313E2F3D0>}\n"
     ]
    }
   ],
   "source": [
    "# ---- Finding the Best Hyperparameters for the Model ----\n",
    "#\n",
    "# - using Randomized Search CV in order to find the best Hyperparameters Values.\n",
    "#\n",
    "hyperparameters_tuning_values = find_best_hyperparameters_values(\n",
    "    model=SVD\n",
    "    , search_cv=RandomizedSearchCV\n",
    "    , parameters=SVD_PARAMS\n",
    "    , dataset=hyperparameter_tuning_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "157ee87f-fe93-4a24-a3e8-421e1df1af50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Finding the Best Hyperparameters for the Model ----\n",
    "#\n",
    "# - getting the model with the best parameters.\n",
    "#\n",
    "chosen_svd_model = hyperparameters_tuning_values.best_estimator['rmse']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8fa92c-f4b9-45f1-b508-ca2f8dca9bc0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**- Splitting Dataset into Training and Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5074bc14-40e2-4601-895e-8ad96de19b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Splitting Dataset into Training and Validation ----\n",
    "#\n",
    "# - converting Pandas DataFrame into Surprise DataFrame\n",
    "#\n",
    "ratings_surprise_df = Dataset.load_from_df(\n",
    "    temp_ratings_df.sample(HYPERPARAMETER_TUNING_SAMPLE_SIZE, random_state=SEED2)\n",
    "    , SURPRISE_READER\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3c1b2db-8023-4cf5-bb96-f79804fc4ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Splitting Dataset into Training and Validation ----\n",
    "#\n",
    "# - deleting some dataframes from the memory since we are going to use 'ratings_surprise_df' from now on;\n",
    "# - datasets to delete:\n",
    "#    \\ ratings_df;\n",
    "#    \\ temp_ratings_df;\n",
    "#    \\ hyperparameter_tuning_df.\n",
    "#\n",
    "ratings_df = None\n",
    "temp_ratings_df = None\n",
    "hyperparameter_tuning_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c0d8fb9-16a2-4acc-8004-ecdef4b39abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Splitting Dataset into Training and Validation ----\n",
    "#\n",
    "# - training: 80%;\n",
    "# - validation: 20%.\n",
    "#\n",
    "training_surprise_df, validation_surprise_df = train_test_split(\n",
    "    data=ratings_surprise_df\n",
    "    , train_size=TRAINING_DF_SIZE\n",
    "    , test_size=VALIDATION_DF_SIZE\n",
    "    , random_state=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d1bab2-ed7f-41ad-900f-0117f701e691",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**- Training the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cafc402e-5203-4619-8bee-19c08a275444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************\n",
      "** Fitting Step **\n",
      "******************\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*********************\n",
      "** Prediction Step **\n",
      "*********************\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*********************\n",
      "** Evaluation Step **\n",
      "*********************\n",
      "\n",
      "\n",
      "RMSE: 0.7426\n",
      "- Root Mean Squared Error (RMSE) for the predictions: 0.7426\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*************************************\n",
      "** Predicting Recommendations Step **\n",
      "*************************************\n",
      "\n",
      "\n",
      "Fitting and Prediction Done üòâüëç\n",
      "\n",
      "\n",
      "***************************\n",
      "** Cross-Validation Step **\n",
      "***************************\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*********************\n",
      "** Validation Step **\n",
      "*********************\n",
      "\n",
      "\n",
      "- Mean Cross-Validation Root Mean Squared Error (RMSE): 0.7412\n",
      "\n",
      "\n",
      "\n",
      "Cross-Validation Done üòâüëç\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---- Training the Model ----\n",
    "#\n",
    "# - creating the model;\n",
    "# - fitting and predicting;\n",
    "# - cross-validating datas.\n",
    "#\n",
    "item_based_recommender = collaborative_filtering_item_based_approach(\n",
    "    chosen_svd_model\n",
    "    , training_surprise_df\n",
    "    , validation_surprise_df\n",
    "    , ratings_surprise_df\n",
    "    , animes_df\n",
    ")\n",
    "\n",
    "model_rmse = item_based_recommender.fit_and_predict(maximum_number_of_recommendations=10, verbose=True)\n",
    "model_cross_validation_rmse = item_based_recommender.cross_validation(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f119134b-cb11-4987-a4e3-ea12114c9971",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**- Recommendations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9be0318-e182-4ac4-b08a-af90e200ce34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************\n",
      "** Recommendations Step **\n",
      "**************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>genres</th>\n",
       "      <th>is_hentai</th>\n",
       "      <th>image_url</th>\n",
       "      <th>predicted_rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18465</th>\n",
       "      <td>genshiken nidaime</td>\n",
       "      <td>7.43</td>\n",
       "      <td>comedy</td>\n",
       "      <td>0</td>\n",
       "      <td>https://cdn.myanimelist.net/images/anime/11/52935.jpg</td>\n",
       "      <td>7.819258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   title  score  genres  is_hentai  \\\n",
       "id                                                   \n",
       "18465  genshiken nidaime   7.43  comedy          0   \n",
       "\n",
       "                                                   image_url  predicted_rating  \n",
       "id                                                                              \n",
       "18465  https://cdn.myanimelist.net/images/anime/11/52935.jpg          7.819258  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations Done, Enjoy üòâüëç\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\joblib\\_memmapping_reducer.py:607: UserWarning: Failed to delete temporary folder: C:\\Users\\gabri\\AppData\\Local\\Temp\\joblib_memmapping_folder_12376_11577afb4583480088fa41abbf558e2f_b8fdf2b5e6a142eb98b3f296f7042c3a\n",
      "  warnings.warn(\"Failed to delete temporary folder: {}\"\n",
      "D:\\Anaconda\\lib\\site-packages\\joblib\\_memmapping_reducer.py:607: UserWarning: Failed to delete temporary folder: C:\\Users\\gabri\\AppData\\Local\\Temp\\joblib_memmapping_folder_12376_24ab6d3db71540bea6403ddf553447e7_a0414323bf63437bbef888892d83c105\n",
      "  warnings.warn(\"Failed to delete temporary folder: {}\"\n",
      "D:\\Anaconda\\lib\\site-packages\\joblib\\_memmapping_reducer.py:607: UserWarning: Failed to delete temporary folder: C:\\Users\\gabri\\AppData\\Local\\Temp\\joblib_memmapping_folder_12376_24ab6d3db71540bea6403ddf553447e7_1ebd058dc7d1495898b9b6008dca7e1e\n",
      "  warnings.warn(\"Failed to delete temporary folder: {}\"\n"
     ]
    }
   ],
   "source": [
    "# ---- Recommendations ----\n",
    "item_based_top_10_animes = item_based_recommender.recommend(\n",
    "    user_id=388_458\n",
    "    , maximum_number_of_recommendations=10\n",
    "    , verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd918ced-a501-4b23-9a43-c2c36fe54d2c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h1 id='reach-me' style='color:#7159c1; border-bottom:3px solid #7159c1; letter-spacing:2px; font-family:JetBrains Mono; font-weight: bold; text-align:left; font-size:240%;padding:0'>üì´ | Reach Me</h1>\n",
    "\n",
    "> **Email** - [csfelix08@gmail.com](mailto:csfelix08@gmail.com?)\n",
    "\n",
    "> **Linkedin** - [linkedin.com/in/csfelix/](https://www.linkedin.com/in/csfelix/)\n",
    "\n",
    "> **GitHub:** - [CSFelix](https://github.com/CSFelix)\n",
    "\n",
    "> **Kaggle** - [DSFelix](https://www.kaggle.com/dsfelix)\n",
    "\n",
    "> **Portfolio** - [CSFelix.io](https://csfelix.github.io/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
